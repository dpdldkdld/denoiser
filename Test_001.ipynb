{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9000a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5fae2c",
   "metadata": {
    "id": "WBZyUMpobR-Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 01:19:05.968226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-04 01:19:09.711238: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-04 01:19:09.725847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-04 01:19:09.747294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:09.747464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-04 01:19:09.747483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-04 01:19:09.820690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-04 01:19:09.820819: I tensorflow/stream_executor/platfo"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2919464505884533051,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 241106944\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 7250386961347856388\n",
       " physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-04 01:19:09.866764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-04 01:19:09.877713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-04 01:19:09.953257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-04 01:19:09.964536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-04 01:19:10.088392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-04 01:19:10.088651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:10.089115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:10.089287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-03-04 01:19:10.089378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-04 01:19:11.718956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-04 01:19:11.718992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-03-04 01:19:11.719000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-03-04 01:19:11.719988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:11.720216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:11.720367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:11.720500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 229 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2022-03-04 01:19:11.721412: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5313ed2c",
   "metadata": {
    "id": "VoyZ5yLRaAeI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 01:19:43.784732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:43.784994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-04 01:19:43.785043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-04 01:19:43.785099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-04 01:19:43.785112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-04 01:19:43.785124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-04 01:19:43.785136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-04 01:19:43.785147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-04 01:19:43.785158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-04 01:19:43.785180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-04 01:19:43.785263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:43.785415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:43.785530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-03-04 01:19:43.785561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-04 01:19:43.785567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-03-04 01:19:43.785572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-03-04 01:19:43.785691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:43.785845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:19:43.785966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 229 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2022-03-04 01:19:43.785982: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "device_name\n",
    "\n",
    "if device_name != '/device:GPU:0' :\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a083796",
   "metadata": {
    "id": "Ah7ISzvtEmur"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import scipy\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import zipfile\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a6000a",
   "metadata": {
    "id": "zu2lgR8lEmu0"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(999)\n",
    "np.random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c97c525",
   "metadata": {
    "id": "JGbkvQHxxrj_"
   },
   "outputs": [],
   "source": [
    "# !wget 'cdn.daitan.com/dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb771bf",
   "metadata": {
    "id": "51o6Ze9hxrkE"
   },
   "outputs": [],
   "source": [
    "# os.getenv('HOME')+'/data'\n",
    "# dataset_file_name = './dataset.zip'\n",
    "# with zipfile.ZipFile(dataset_file_name, 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9901990c",
   "metadata": {
    "id": "d43UvhEqxrkJ"
   },
   "outputs": [],
   "source": [
    "path_to_dataset = os.getenv('HOME')+'/data/tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366dadef",
   "metadata": {
    "id": "W36WF4mT1kGK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file names:  ['/home/seungmiya13/data/tfrecords/train_2.tfrecords', '/home/seungmiya13/data/tfrecords/train_1.tfrecords', '/home/seungmiya13/data/tfrecords/train_0.tfrecords']\n",
      "Validation file names:  ['/home/seungmiya13/data/tfrecords/val_0.tfrecords']\n"
     ]
    }
   ],
   "source": [
    "# get training and validation tf record file names\n",
    "train_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'train_*'))\n",
    "val_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'val_*'))\n",
    "\n",
    "# suffle the file names for training\n",
    "np.random.shuffle(train_tfrecords_filenames)\n",
    "print(\"Training file names: \", train_tfrecords_filenames)\n",
    "print(\"Validation file names: \", val_tfrecords_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c9f9b6",
   "metadata": {
    "id": "jKZtPoLMEmvJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windowLength: 256\n",
      "overlap: 64\n",
      "ffTLength: 256\n",
      "inputFs: 48000.0\n",
      "fs: 16000.0\n",
      "numFeatures: 129\n",
      "numSegments: 8\n"
     ]
    }
   ],
   "source": [
    "windowLength = 256\n",
    "overlap      = round(0.25 * windowLength) # overlap of 75%\n",
    "ffTLength    = windowLength\n",
    "inputFs      = 48e3\n",
    "fs           = 16e3\n",
    "numFeatures  = ffTLength//2 + 1\n",
    "numSegments  = 8\n",
    "print(\"windowLength:\",windowLength)\n",
    "print(\"overlap:\",overlap)\n",
    "print(\"ffTLength:\",ffTLength)\n",
    "print(\"inputFs:\",inputFs)\n",
    "print(\"fs:\",fs)\n",
    "print(\"numFeatures:\",numFeatures)\n",
    "print(\"numSegments:\",numSegments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ee1f27d",
   "metadata": {
    "id": "JXpSGe8L0cl_"
   },
   "outputs": [],
   "source": [
    "mozilla_basepath = os.getenv('HOME')+ \"/data/en\"\n",
    "UrbanSound8K_basepath = os.getenv('HOME')+ '/data/UrbanSound8K'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac3f46b",
   "metadata": {
    "id": "zzbdfIi-Lgk9"
   },
   "source": [
    "## Prepare Input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8df8d3dd",
   "metadata": {
    "id": "24kph3wJ3s5V"
   },
   "outputs": [],
   "source": [
    "def tf_record_parser(record):\n",
    "    keys_to_features = {\n",
    "        \"noise_stft_phase\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        'noise_stft_mag_features': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"clean_stft_magnitude\": tf.io.FixedLenFeature((), tf.string)\n",
    "    }\n",
    "\n",
    "    features = tf.io.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    noise_stft_mag_features = tf.io.decode_raw(features['noise_stft_mag_features'], tf.float32)\n",
    "    clean_stft_magnitude = tf.io.decode_raw(features['clean_stft_magnitude'], tf.float32)\n",
    "    noise_stft_phase = tf.io.decode_raw(features['noise_stft_phase'], tf.float32)\n",
    "\n",
    "    # reshape input and annotation images\n",
    "    noise_stft_mag_features = tf.reshape(noise_stft_mag_features, (129, 8, 1), name=\"noise_stft_mag_features\")\n",
    "    clean_stft_magnitude = tf.reshape(clean_stft_magnitude, (129, 1, 1), name=\"clean_stft_magnitude\")\n",
    "    noise_stft_phase = tf.reshape(noise_stft_phase, (129,), name=\"noise_stft_phase\")\n",
    "\n",
    "    return noise_stft_mag_features, clean_stft_magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e5108c",
   "metadata": {
    "id": "uJXPGrgVTCbZ"
   },
   "source": [
    "## Create tf.Data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "181af56e",
   "metadata": {
    "id": "FF_A3YbZTCsj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function tf_record_parser at 0x7f4eb86e4a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function tf_record_parser at 0x7f4eb86e4a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 01:21:55.336146: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-04 01:21:55.336454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:21:55.336653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-04 01:21:55.336706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-04 01:21:55.336762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-04 01:21:55.336776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-04 01:21:55.336789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-04 01:21:55.336802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-04 01:21:55.336817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-04 01:21:55.336833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-04 01:21:55.336846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-04 01:21:55.336935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:21:55.337121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:21:55.337234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-03-04 01:21:55.337787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:21:55.337927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-04 01:21:55.337946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-04 01:21:55.337965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-04 01:21:55.337976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-04 01:21:55.337985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-04 01:21:55.337994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-04 01:21:55.338004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-04 01:21:55.338013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-04 01:21:55.338023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-04 01:21:55.338067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:21:55.338210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:21:55.338321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-03-04 01:21:55.338369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-04 01:21:55.338375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-03-04 01:21:55.338380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-03-04 01:21:55.338469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:21:55.338653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-04 01:21:55.338795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 229 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2022-03-04 01:21:55.338816: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.TFRecordDataset([train_tfrecords_filenames])\n",
    "train_dataset = train_dataset.map(tf_record_parser)\n",
    "train_dataset = train_dataset.shuffle(8192)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.batch(512)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f91c2c2d",
   "metadata": {
    "id": "NOuWPzQaTNDy"
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.TFRecordDataset([val_tfrecords_filenames])\n",
    "test_dataset = test_dataset.map(tf_record_parser)\n",
    "test_dataset = test_dataset.repeat(1)\n",
    "test_dataset = test_dataset.batch(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57958e",
   "metadata": {
    "id": "CEG5JofLSfRw"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db3b79c3",
   "metadata": {
    "id": "2OZFegXrSYle"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n",
    "from tensorflow.keras import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46534ba2",
   "metadata": {
    "id": "lc2K0cfhPU5-"
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
    "  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  if use_bn:\n",
    "    x = BatchNormalization()(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d76f334",
   "metadata": {
    "id": "XFYyKoAVQYCz"
   },
   "outputs": [],
   "source": [
    "def full_pre_activation_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
    "  shortcut = x\n",
    "  in_channels = x.shape[-1]\n",
    "\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters=in_channels, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "\n",
    "  return shortcut + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fea4dfc",
   "metadata": {
    "id": "NlRQ3ngpZG1Y"
   },
   "outputs": [],
   "source": [
    "def build_model(l2_strength):\n",
    "  inputs = Input(shape=[numFeatures,numSegments,1])\n",
    "  x = inputs\n",
    "\n",
    "  # -----\n",
    "  x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n",
    "  x = Conv2D(filters=18, kernel_size=[9,8], strides=[1, 1], padding='valid', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  skip0 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(skip0)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # -----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  skip1 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(skip1)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = x + skip1\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = x + skip0\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n",
    "  x = Conv2D(filters=1, kernel_size=[129,1], strides=[1, 1], padding='same')(x)\n",
    "\n",
    "  model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(3e-4)\n",
    "  #optimizer = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=3e-4)\n",
    "\n",
    "  model.compile(optimizer=optimizer, loss='mse', \n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError('rmse')])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6231c0d6",
   "metadata": {
    "id": "mNpHS4LuShxd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 129, 8, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 137, 8, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 129, 1, 18)   1296        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 129, 1, 18)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 129, 1, 18)   72          activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 129, 1, 30)   2700        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 129, 1, 30)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 129, 1, 30)   120         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 129, 1, 8)    2160        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 129, 1, 8)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 129, 1, 8)    32          activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 129, 1, 18)   1296        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 129, 1, 18)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 129, 1, 18)   72          activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 129, 1, 30)   2700        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 129, 1, 30)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 129, 1, 30)   120         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 129, 1, 8)    2160        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 129, 1, 8)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 129, 1, 8)    32          activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 129, 1, 18)   1296        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 129, 1, 18)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 129, 1, 18)   72          activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 129, 1, 30)   2700        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 129, 1, 30)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 129, 1, 30)   120         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 129, 1, 8)    2160        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 129, 1, 8)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 129, 1, 8)    32          activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 129, 1, 18)   1296        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 129, 1, 18)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 129, 1, 18)   72          activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 129, 1, 30)   2700        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 129, 1, 30)   0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 129, 1, 30)   0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 129, 1, 30)   120         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 129, 1, 8)    2160        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 129, 1, 8)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 129, 1, 8)    32          activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 129, 1, 18)   1296        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 129, 1, 18)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 129, 1, 18)   72          activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 129, 1, 30)   2700        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 129, 1, 30)   0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 129, 1, 30)   0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 129, 1, 30)   120         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 129, 1, 8)    2160        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 129, 1, 8)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 129, 1, 8)    32          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d (SpatialDropo (None, 129, 1, 8)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 129, 1, 1)    1033        spatial_dropout2d[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 32,933\n",
      "Trainable params: 32,373\n",
      "Non-trainable params: 560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(l2_strength=0.0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c776a52",
   "metadata": {
    "id": "8rWOgsdwglFE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# You might need to install the following dependencies: sudo apt install python-pydot python-pydot-ng graphviz\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0009f289",
   "metadata": {
    "id": "7OdmgHTp4_Ou"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8993a80f3a3a48c6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8993a80f3a3a48c6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d7c2139",
   "metadata": {
    "id": "BucSAwkHQj8Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 01:23:46.019033: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-03-04 01:23:46.020232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
      "2022-03-04 01:23:46.438148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-04 01:23:47.567564: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-03-04 01:23:47.570660: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv2d/Conv2D (defined at tmp/ipykernel_20355/3149148983.py:1) ]] [Op:__inference_test_function_1431]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20355/3149148983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Baseline accuracy {baseline_val_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiing2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiing2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiing2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 895\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiing2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiing2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aiing2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv2d/Conv2D (defined at tmp/ipykernel_20355/3149148983.py:1) ]] [Op:__inference_test_function_1431]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "baseline_val_loss = model.evaluate(test_dataset)[0]\n",
    "print(f\"Baseline accuracy {baseline_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48e90bad",
   "metadata": {
    "id": "ocycFbP5-X0o"
   },
   "outputs": [],
   "source": [
    "def l2_norm(vector):\n",
    "    return np.square(vector)\n",
    "\n",
    "def SDR(denoised, cleaned, eps=1e-7): # Signal to Distortion Ratio\n",
    "    a = l2_norm(denoised)\n",
    "    b = l2_norm(denoised - cleaned)\n",
    "    a_b = a / b\n",
    "    return np.mean(10 * np.log10(a_b + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167d19a",
   "metadata": {
    "id": "bcPAuMZ9SlHa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 13:06:38.444618: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2022-03-02 13:06:38.446030: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1363] Profiler found 1 GPUs\n",
      "2022-03-02 13:06:38.446397: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory\n",
      "2022-03-02 13:06:38.446412: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-03-02 13:06:38.446420: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-03-02 13:06:38.446446: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/600 [..............................] - ETA: 0s - loss: 2.2662 - rmse: 1.5054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 13:06:41.411489: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2022-03-02 13:06:41.411567: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-03-02 13:06:41.411580: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/600 [..............................] - ETA: 4:36 - loss: 2.2193 - rmse: 1.4897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 13:06:42.267682: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-03-02 13:06:42.275042: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 0 callback api events and 0 activity events.\n",
      "2022-03-02 13:06:42.301702: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs/20220302-130638/train/plugins/profile/2022_03_02_13_06_42\n",
      "2022-03-02 13:06:42.321720: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs/20220302-130638/train/plugins/profile/2022_03_02_13_06_42/aiing2.trace.json.gz\n",
      "2022-03-02 13:06:42.331829: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.001 ms\n",
      "\n",
      "2022-03-02 13:06:42.333996: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: logs/20220302-130638/train/plugins/profile/2022_03_02_13_06_42Dumped tool data for overview_page.pb to logs/20220302-130638/train/plugins/profile/2022_03_02_13_06_42/aiing2.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/20220302-130638/train/plugins/profile/2022_03_02_13_06_42/aiing2.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/20220302-130638/train/plugins/profile/2022_03_02_13_06_42/aiing2.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/20220302-130638/train/plugins/profile/2022_03_02_13_06_42/aiing2.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 557s 929ms/step - loss: 0.3851 - rmse: 0.6206 - val_loss: 0.2462 - val_rmse: 0.4962\n",
      "Epoch 2/400\n",
      "600/600 [==============================] - 549s 915ms/step - loss: 0.2305 - rmse: 0.4801 - val_loss: 0.2272 - val_rmse: 0.4767\n",
      "Epoch 3/400\n",
      "600/600 [==============================] - 548s 913ms/step - loss: 0.2098 - rmse: 0.4581 - val_loss: 0.2122 - val_rmse: 0.4606\n",
      "Epoch 4/400\n",
      "600/600 [==============================] - 547s 911ms/step - loss: 0.2032 - rmse: 0.4508 - val_loss: 0.1924 - val_rmse: 0.4386\n",
      "Epoch 5/400\n",
      "600/600 [==============================] - 545s 908ms/step - loss: 0.1927 - rmse: 0.4390 - val_loss: 0.2062 - val_rmse: 0.4541\n",
      "Epoch 6/400\n",
      "600/600 [==============================] - 548s 914ms/step - loss: 0.1893 - rmse: 0.4351 - val_loss: 0.1918 - val_rmse: 0.4380\n",
      "Epoch 7/400\n",
      "600/600 [==============================] - 550s 916ms/step - loss: 0.1836 - rmse: 0.4285 - val_loss: 0.1851 - val_rmse: 0.4303\n",
      "Epoch 8/400\n",
      "600/600 [==============================] - 543s 905ms/step - loss: 0.1791 - rmse: 0.4232 - val_loss: 0.1969 - val_rmse: 0.4437\n",
      "Epoch 9/400\n",
      "600/600 [==============================] - 543s 906ms/step - loss: 0.1745 - rmse: 0.4178 - val_loss: 0.1771 - val_rmse: 0.4208\n",
      "Epoch 10/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1721 - rmse: 0.4149 - val_loss: 0.1851 - val_rmse: 0.4302\n",
      "Epoch 11/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1749 - rmse: 0.4182 - val_loss: 0.1959 - val_rmse: 0.4426\n",
      "Epoch 12/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1698 - rmse: 0.4121 - val_loss: 0.1777 - val_rmse: 0.4215\n",
      "Epoch 13/400\n",
      "600/600 [==============================] - 544s 907ms/step - loss: 0.1683 - rmse: 0.4103 - val_loss: 0.1792 - val_rmse: 0.4234\n",
      "Epoch 14/400\n",
      "600/600 [==============================] - 563s 938ms/step - loss: 0.1664 - rmse: 0.4080 - val_loss: 0.1809 - val_rmse: 0.4253\n",
      "Epoch 15/400\n",
      "600/600 [==============================] - 619s 1s/step - loss: 0.1649 - rmse: 0.4061 - val_loss: 0.1823 - val_rmse: 0.4270\n",
      "Epoch 16/400\n",
      "600/600 [==============================] - 549s 915ms/step - loss: 0.1612 - rmse: 0.4015 - val_loss: 0.1721 - val_rmse: 0.4148\n",
      "Epoch 17/400\n",
      "600/600 [==============================] - 554s 924ms/step - loss: 0.1610 - rmse: 0.4013 - val_loss: 0.1721 - val_rmse: 0.4149\n",
      "Epoch 18/400\n",
      "600/600 [==============================] - 551s 919ms/step - loss: 0.1616 - rmse: 0.4020 - val_loss: 0.1798 - val_rmse: 0.4240\n",
      "Epoch 19/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1627 - rmse: 0.4034 - val_loss: 0.1839 - val_rmse: 0.4288\n",
      "Epoch 20/400\n",
      "600/600 [==============================] - 540s 900ms/step - loss: 0.1578 - rmse: 0.3973 - val_loss: 0.1846 - val_rmse: 0.4296\n",
      "Epoch 21/400\n",
      "600/600 [==============================] - 539s 899ms/step - loss: 0.1602 - rmse: 0.4003 - val_loss: 0.1736 - val_rmse: 0.4167\n",
      "Epoch 22/400\n",
      "600/600 [==============================] - 539s 898ms/step - loss: 0.1573 - rmse: 0.3966 - val_loss: 0.1803 - val_rmse: 0.4247\n",
      "Epoch 23/400\n",
      "600/600 [==============================] - 539s 899ms/step - loss: 0.1570 - rmse: 0.3963 - val_loss: 0.1761 - val_rmse: 0.4196\n",
      "Epoch 24/400\n",
      "600/600 [==============================] - 543s 905ms/step - loss: 0.1546 - rmse: 0.3932 - val_loss: 0.2084 - val_rmse: 0.4566\n",
      "Epoch 25/400\n",
      "600/600 [==============================] - 544s 907ms/step - loss: 0.1560 - rmse: 0.3950 - val_loss: 0.1723 - val_rmse: 0.4151\n",
      "Epoch 26/400\n",
      "600/600 [==============================] - 542s 904ms/step - loss: 0.1577 - rmse: 0.3971 - val_loss: 0.1733 - val_rmse: 0.4163\n",
      "Epoch 27/400\n",
      "600/600 [==============================] - 546s 910ms/step - loss: 0.1555 - rmse: 0.3944 - val_loss: 0.1681 - val_rmse: 0.4100\n",
      "Epoch 28/400\n",
      "600/600 [==============================] - 545s 908ms/step - loss: 0.1556 - rmse: 0.3945 - val_loss: 0.1730 - val_rmse: 0.4159\n",
      "Epoch 29/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1530 - rmse: 0.3912 - val_loss: 0.1678 - val_rmse: 0.4096\n",
      "Epoch 30/400\n",
      "600/600 [==============================] - 538s 897ms/step - loss: 0.1553 - rmse: 0.3941 - val_loss: 0.1657 - val_rmse: 0.4071\n",
      "Epoch 31/400\n",
      "600/600 [==============================] - 537s 895ms/step - loss: 0.1513 - rmse: 0.3890 - val_loss: 0.1690 - val_rmse: 0.4111\n",
      "Epoch 32/400\n",
      "600/600 [==============================] - 540s 900ms/step - loss: 0.1519 - rmse: 0.3897 - val_loss: 0.1703 - val_rmse: 0.4127\n",
      "Epoch 33/400\n",
      "600/600 [==============================] - 544s 906ms/step - loss: 0.1558 - rmse: 0.3947 - val_loss: 0.1651 - val_rmse: 0.4063\n",
      "Epoch 34/400\n",
      "600/600 [==============================] - 539s 898ms/step - loss: 0.1516 - rmse: 0.3894 - val_loss: 0.1702 - val_rmse: 0.4125\n",
      "Epoch 35/400\n",
      "600/600 [==============================] - 539s 899ms/step - loss: 0.1533 - rmse: 0.3916 - val_loss: 0.1889 - val_rmse: 0.4347\n",
      "Epoch 36/400\n",
      "600/600 [==============================] - 540s 900ms/step - loss: 0.1527 - rmse: 0.3908 - val_loss: 0.1652 - val_rmse: 0.4065\n",
      "Epoch 37/400\n",
      "600/600 [==============================] - 540s 900ms/step - loss: 0.1508 - rmse: 0.3884 - val_loss: 0.1646 - val_rmse: 0.4057\n",
      "Epoch 38/400\n",
      "600/600 [==============================] - 541s 902ms/step - loss: 0.1503 - rmse: 0.3877 - val_loss: 0.1668 - val_rmse: 0.4085\n",
      "Epoch 39/400\n",
      "600/600 [==============================] - 540s 899ms/step - loss: 0.1503 - rmse: 0.3876 - val_loss: 0.1727 - val_rmse: 0.4155\n",
      "Epoch 40/400\n",
      "600/600 [==============================] - 536s 894ms/step - loss: 0.1521 - rmse: 0.3900 - val_loss: 0.1731 - val_rmse: 0.4161\n",
      "Epoch 41/400\n",
      "600/600 [==============================] - 540s 899ms/step - loss: 0.1514 - rmse: 0.3891 - val_loss: 0.1878 - val_rmse: 0.4334\n",
      "Epoch 42/400\n",
      "600/600 [==============================] - 537s 895ms/step - loss: 0.1500 - rmse: 0.3873 - val_loss: 0.1701 - val_rmse: 0.4124\n",
      "Epoch 43/400\n",
      "600/600 [==============================] - 539s 898ms/step - loss: 0.1521 - rmse: 0.3901 - val_loss: 0.1666 - val_rmse: 0.4081\n",
      "Epoch 44/400\n",
      "600/600 [==============================] - 540s 900ms/step - loss: 0.1500 - rmse: 0.3873 - val_loss: 0.1605 - val_rmse: 0.4006\n",
      "Epoch 45/400\n",
      "600/600 [==============================] - 547s 912ms/step - loss: 0.1487 - rmse: 0.3856 - val_loss: 0.1628 - val_rmse: 0.4035\n",
      "Epoch 46/400\n",
      "600/600 [==============================] - 552s 920ms/step - loss: 0.1487 - rmse: 0.3856 - val_loss: 0.1601 - val_rmse: 0.4001\n",
      "Epoch 47/400\n",
      "600/600 [==============================] - 543s 905ms/step - loss: 0.1499 - rmse: 0.3871 - val_loss: 0.1629 - val_rmse: 0.4035\n",
      "Epoch 48/400\n",
      "600/600 [==============================] - 541s 901ms/step - loss: 0.1510 - rmse: 0.3886 - val_loss: 0.1655 - val_rmse: 0.4068\n",
      "Epoch 49/400\n",
      "600/600 [==============================] - 540s 900ms/step - loss: 0.1490 - rmse: 0.3861 - val_loss: 0.1734 - val_rmse: 0.4164\n",
      "Epoch 50/400\n",
      "600/600 [==============================] - 540s 899ms/step - loss: 0.1502 - rmse: 0.3875 - val_loss: 0.1589 - val_rmse: 0.3987\n",
      "Epoch 51/400\n",
      "600/600 [==============================] - 538s 897ms/step - loss: 0.1475 - rmse: 0.3840 - val_loss: 0.1658 - val_rmse: 0.4072\n",
      "Epoch 52/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1501 - rmse: 0.3874 - val_loss: 0.1694 - val_rmse: 0.4116\n",
      "Epoch 53/400\n",
      "600/600 [==============================] - 542s 904ms/step - loss: 0.1465 - rmse: 0.3828 - val_loss: 0.1614 - val_rmse: 0.4017\n",
      "Epoch 54/400\n",
      "600/600 [==============================] - 540s 899ms/step - loss: 0.1476 - rmse: 0.3841 - val_loss: 0.1723 - val_rmse: 0.4151\n",
      "Epoch 55/400\n",
      "600/600 [==============================] - 540s 901ms/step - loss: 0.1506 - rmse: 0.3881 - val_loss: 0.1636 - val_rmse: 0.4045\n",
      "Epoch 56/400\n",
      "600/600 [==============================] - 540s 899ms/step - loss: 0.1475 - rmse: 0.3841 - val_loss: 0.1568 - val_rmse: 0.3960\n",
      "Epoch 57/400\n",
      "600/600 [==============================] - 543s 905ms/step - loss: 0.1484 - rmse: 0.3853 - val_loss: 0.1593 - val_rmse: 0.3991\n",
      "Epoch 58/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1482 - rmse: 0.3849 - val_loss: 0.1621 - val_rmse: 0.4026\n",
      "Epoch 59/400\n",
      "600/600 [==============================] - 545s 909ms/step - loss: 0.1476 - rmse: 0.3842 - val_loss: 0.1648 - val_rmse: 0.4059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/400\n",
      "600/600 [==============================] - 545s 908ms/step - loss: 0.1460 - rmse: 0.3820 - val_loss: 0.1630 - val_rmse: 0.4038\n",
      "Epoch 61/400\n",
      "600/600 [==============================] - 544s 906ms/step - loss: 0.1455 - rmse: 0.3814 - val_loss: 0.1614 - val_rmse: 0.4017\n",
      "Epoch 62/400\n",
      "600/600 [==============================] - 542s 904ms/step - loss: 0.1502 - rmse: 0.3875 - val_loss: 0.1660 - val_rmse: 0.4075\n",
      "Epoch 63/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1469 - rmse: 0.3833 - val_loss: 0.1569 - val_rmse: 0.3962\n",
      "Epoch 64/400\n",
      "600/600 [==============================] - 541s 902ms/step - loss: 0.1475 - rmse: 0.3841 - val_loss: 0.1707 - val_rmse: 0.4132\n",
      "Epoch 65/400\n",
      "600/600 [==============================] - 541s 901ms/step - loss: 0.1471 - rmse: 0.3835 - val_loss: 0.1681 - val_rmse: 0.4100\n",
      "Epoch 66/400\n",
      "600/600 [==============================] - 541s 902ms/step - loss: 0.1476 - rmse: 0.3842 - val_loss: 0.1751 - val_rmse: 0.4184\n",
      "Epoch 67/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1449 - rmse: 0.3806 - val_loss: 0.1714 - val_rmse: 0.4140\n",
      "Epoch 68/400\n",
      "600/600 [==============================] - 544s 907ms/step - loss: 0.1459 - rmse: 0.3820 - val_loss: 0.1698 - val_rmse: 0.4120\n",
      "Epoch 69/400\n",
      "600/600 [==============================] - 540s 900ms/step - loss: 0.1465 - rmse: 0.3828 - val_loss: 0.1590 - val_rmse: 0.3987\n",
      "Epoch 70/400\n",
      "600/600 [==============================] - 542s 903ms/step - loss: 0.1487 - rmse: 0.3856 - val_loss: 0.1597 - val_rmse: 0.3997\n",
      "Epoch 71/400\n",
      "600/600 [==============================] - 544s 906ms/step - loss: 0.1446 - rmse: 0.3802 - val_loss: 0.1654 - val_rmse: 0.4067\n",
      "Epoch 72/400\n",
      "600/600 [==============================] - 547s 911ms/step - loss: 0.1478 - rmse: 0.3844 - val_loss: 0.1581 - val_rmse: 0.3976\n",
      "Epoch 73/400\n",
      "600/600 [==============================] - 548s 913ms/step - loss: 0.1460 - rmse: 0.3821 - val_loss: 0.1639 - val_rmse: 0.4048\n",
      "Epoch 74/400\n",
      "600/600 [==============================] - 544s 907ms/step - loss: 0.1455 - rmse: 0.3814 - val_loss: 0.1578 - val_rmse: 0.3972\n",
      "Epoch 75/400\n",
      "600/600 [==============================] - 540s 899ms/step - loss: 0.1443 - rmse: 0.3799 - val_loss: 0.1574 - val_rmse: 0.3967\n",
      "Epoch 76/400\n",
      "600/600 [==============================] - 541s 901ms/step - loss: 0.1456 - rmse: 0.3815 - val_loss: 0.1609 - val_rmse: 0.4011\n",
      "Epoch 77/400\n",
      "600/600 [==============================] - 546s 910ms/step - loss: 0.1474 - rmse: 0.3840 - val_loss: 0.1734 - val_rmse: 0.4165\n",
      "Epoch 78/400\n",
      "600/600 [==============================] - 547s 911ms/step - loss: 0.1455 - rmse: 0.3815 - val_loss: 0.1615 - val_rmse: 0.4018\n",
      "Epoch 79/400\n",
      " 26/600 [>.............................] - ETA: 7:08 - loss: 0.1431 - rmse: 0.3782"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, baseline=None)\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq='batch')\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./denoiser_cnn_log_mel_generator.h5', \n",
    "                                                         monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(train_dataset,\n",
    "         steps_per_epoch=600, # you might need to change this\n",
    "         validation_data=test_dataset,\n",
    "         epochs=400,\n",
    "         callbacks=[early_stopping_callback, tensorboard_callback, checkpoint_callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786720f",
   "metadata": {
    "id": "g1ZZskDZ5L2a"
   },
   "outputs": [],
   "source": [
    "val_loss = model.evaluate(test_dataset)[0]\n",
    "if val_loss < baseline_val_loss:\n",
    "  print(\"New model saved.\")\n",
    "  model.save('./denoiser_cnn_log_mel_generator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd912f70",
   "metadata": {
    "id": "LeJTsGxCSuhm"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b210d4",
   "metadata": {
    "id": "DLiTiK8blE0n"
   },
   "outputs": [],
   "source": [
    "def read_audio(filepath, sample_rate, normalize=True):\n",
    "    \"\"\"Read an audio file and return it as a numpy array\"\"\"\n",
    "    audio, sr = librosa.load(filepath, sr=sample_rate)\n",
    "    if normalize:\n",
    "      div_fac = 1 / np.max(np.abs(audio)) / 3.0\n",
    "      audio = audio * div_fac\n",
    "    return audio, sr\n",
    "        \n",
    "def add_noise_to_clean_audio(clean_audio, noise_signal):\n",
    "    \"\"\"Adds noise to an audio sample\"\"\"\n",
    "    if len(clean_audio) >= len(noise_signal):\n",
    "        # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n",
    "        while len(clean_audio) >= len(noise_signal):\n",
    "            noise_signal = np.append(noise_signal, noise_signal)\n",
    "\n",
    "    ## Extract a noise segment from a random location in the noise file\n",
    "    ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n",
    "\n",
    "    noiseSegment = noise_signal[ind: ind + clean_audio.size]\n",
    "\n",
    "    speech_power = np.sum(clean_audio ** 2)\n",
    "    noise_power = np.sum(noiseSegment ** 2)\n",
    "    noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n",
    "    return noisyAudio\n",
    "\n",
    "def play(audio, sample_rate):\n",
    "    ipd.display(ipd.Audio(data=audio, rate=sample_rate))  # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e92e3",
   "metadata": {
    "id": "uM6ajbBFlx3b"
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n",
    "        self.audio = audio\n",
    "        self.ffT_length = windowLength\n",
    "        self.window_length = windowLength\n",
    "        self.overlap = overlap\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window = scipy.signal.hamming(self.window_length, sym=False)\n",
    "\n",
    "    def get_stft_spectrogram(self):\n",
    "        return librosa.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n",
    "                            window=self.window, center=True)\n",
    "\n",
    "    def get_audio_from_stft_spectrogram(self, stft_features):\n",
    "        return librosa.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n",
    "                             window=self.window, center=True)\n",
    "\n",
    "    def get_mel_spectrogram(self):\n",
    "        return librosa.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, pad_mode='reflect',\n",
    "                                           n_fft=self.ffT_length, hop_length=self.overlap, center=True)\n",
    "\n",
    "    def get_audio_from_mel_spectrogram(self, M):\n",
    "        return librosa.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length, hop_length=self.overlap,\n",
    "                                             win_length=self.window_length, window=self.window,\n",
    "                                             center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0dfaa5",
   "metadata": {
    "id": "9dcnyvquSoLs"
   },
   "outputs": [],
   "source": [
    "cleanAudio, sr = read_audio(os.path.join(mozilla_basepath, 'test', 'common_voice_en_16526.mp3'), sample_rate=fs)\n",
    "print(\"Min:\", np.min(cleanAudio),\"Max:\",np.max(cleanAudio))\n",
    "ipd.Audio(data=cleanAudio, rate=sr) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac7c9e2",
   "metadata": {
    "id": "BaHe1okPTvV-"
   },
   "outputs": [],
   "source": [
    "noiseAudio, sr = read_audio(os.path.join(UrbanSound8K_basepath, 'test', '7913-3-0-0.wav'), sample_rate=fs)\n",
    "print(\"Min:\", np.min(noiseAudio),\"Max:\",np.max(noiseAudio))\n",
    "ipd.Audio(data=noiseAudio, rate=sr) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140070db",
   "metadata": {
    "id": "bu_eOKRfTHbp"
   },
   "outputs": [],
   "source": [
    "cleanAudioFeatureExtractor = FeatureExtractor(cleanAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "stft_features = cleanAudioFeatureExtractor.get_stft_spectrogram()\n",
    "stft_features = np.abs(stft_features)\n",
    "print(\"Min:\", np.min(stft_features),\"Max:\",np.max(stft_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e95c4",
   "metadata": {
    "id": "sHWcmobyTP4E"
   },
   "outputs": [],
   "source": [
    "noisyAudio = add_noise_to_clean_audio(cleanAudio, noiseAudio)\n",
    "ipd.Audio(data=noisyAudio, rate=fs) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b5631",
   "metadata": {
    "id": "75M29dl3bBeF"
   },
   "outputs": [],
   "source": [
    "def prepare_input_features(stft_features):\n",
    "    # Phase Aware Scaling: To avoid extreme differences (more than\n",
    "    # 45 degree) between the noisy and clean phase, the clean spectral magnitude was encoded as similar to [21]:\n",
    "    noisySTFT = np.concatenate([stft_features[:,0:numSegments-1], stft_features], axis=1)\n",
    "    stftSegments = np.zeros((numFeatures, numSegments , noisySTFT.shape[1] - numSegments + 1))\n",
    "\n",
    "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
    "        stftSegments[:,:,index] = noisySTFT[:,index:index + numSegments]\n",
    "    return stftSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669267af",
   "metadata": {
    "id": "9cjO5-cjTP6t"
   },
   "outputs": [],
   "source": [
    "noiseAudioFeatureExtractor = FeatureExtractor(noisyAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "noise_stft_features = noiseAudioFeatureExtractor.get_stft_spectrogram()\n",
    "\n",
    "# Paper: Besides, spectral phase was not used in the training phase.\n",
    "# At reconstruction, noisy spectral phase was used instead to\n",
    "# perform in- verse STFT and recover human speech.\n",
    "noisyPhase = np.angle(noise_stft_features)\n",
    "print(noisyPhase.shape)\n",
    "noise_stft_features = np.abs(noise_stft_features)\n",
    "\n",
    "mean = np.mean(noise_stft_features)\n",
    "std = np.std(noise_stft_features)\n",
    "noise_stft_features = (noise_stft_features - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246277bb",
   "metadata": {
    "id": "3p5PWWkrlE3m"
   },
   "outputs": [],
   "source": [
    "predictors = prepare_input_features(noise_stft_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b161fc5",
   "metadata": {
    "id": "4pSoOw2fTP9N"
   },
   "outputs": [],
   "source": [
    "predictors = np.reshape(predictors, (predictors.shape[0], predictors.shape[1], 1, predictors.shape[2]))\n",
    "predictors = np.transpose(predictors, (3, 0, 1, 2)).astype(np.float32)\n",
    "print('predictors.shape:', predictors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c2116",
   "metadata": {
    "id": "a5sNR4sSTP_1"
   },
   "outputs": [],
   "source": [
    "STFTFullyConvolutional = model.predict(predictors)\n",
    "print(STFTFullyConvolutional.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91083250",
   "metadata": {
    "id": "LzCga3PdUVwG"
   },
   "outputs": [],
   "source": [
    "def revert_features_to_audio(features, phase, cleanMean=None, cleanStd=None):\n",
    "    # scale the outpus back to the original range\n",
    "    if cleanMean and cleanStd:\n",
    "        features = cleanStd * features + cleanMean\n",
    "\n",
    "    phase = np.transpose(phase, (1, 0))\n",
    "    features = np.squeeze(features)\n",
    "\n",
    "    # features = librosa.db_to_power(features)\n",
    "    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n",
    "\n",
    "    features = np.transpose(features, (1, 0))\n",
    "    return noiseAudioFeatureExtractor.get_audio_from_stft_spectrogram(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538962ab",
   "metadata": {
    "id": "LWlUDtPzURlQ"
   },
   "outputs": [],
   "source": [
    "denoisedAudioFullyConvolutional = revert_features_to_audio(STFTFullyConvolutional, noisyPhase, mean, std)\n",
    "print(\"Min:\", np.min(denoisedAudioFullyConvolutional),\"Max:\",np.max(denoisedAudioFullyConvolutional))\n",
    "ipd.Audio(data=denoisedAudioFullyConvolutional, rate=fs) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3590177",
   "metadata": {
    "id": "VvEIBy7EHgeP"
   },
   "outputs": [],
   "source": [
    "# A numeric identifier of the sound class -- Types of noise\n",
    "# 0 = air_conditioner\n",
    "# 1 = car_horn\n",
    "# 2 = children_playing\n",
    "# 3 = dog_bark\n",
    "# 4 = drilling\n",
    "# 5 = engine_idling\n",
    "# 6 = gun_shot\n",
    "# 7 = jackhammer\n",
    "# 8 = siren\n",
    "# 9 = street_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a080f",
   "metadata": {
    "id": "tv_7ZwWaUW0_"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharey=True)\n",
    "\n",
    "ax1.plot(cleanAudio)\n",
    "ax1.set_title(\"Clean Audio\")\n",
    "\n",
    "ax2.plot(noisyAudio)\n",
    "ax2.set_title(\"Noisy Audio\")\n",
    "\n",
    "ax3.plot(denoisedAudioFullyConvolutional)\n",
    "ax3.set_title(\"Denoised Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c49f5",
   "metadata": {
    "id": "8LM7E91avKA3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909551c",
   "metadata": {
    "id": "VoyZ5yLRaAeI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "device_name\n",
    "# if device_name != '/device:XLA_GPUGPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "!nvcc --version\n",
    "\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import scipy\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import zipfile\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.zeros((129,8,1)).shape\n",
    "\n",
    "tf.random.set_seed(999)\n",
    "np.random.seed(999)\n",
    "\n",
    "!python data_processing/urban_sound_8K.py\n",
    "!python data_processing/mozilla_common_voice.py\n",
    "!python data_processing/feature_extractor.py\n",
    "!python data_processing/dataset.py\n",
    "\n",
    "!python data_processing/create_dataset.py\n",
    "\n",
    "# !wget 'cdn.daitan.com/dataset.zip'\n",
    "\n",
    "# os.getenv('HOME')+'/data'\n",
    "dataset_file_name = './dataset.zip'\n",
    "with zipfile.ZipFile(dataset_file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./dataset')\n",
    "\n",
    "path_to_dataset = os.getenv('HOME')+'/data/tfrecords'\n",
    "\n",
    "# get training and validation tf record file names\n",
    "train_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'train_*'))\n",
    "val_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'val_*'))\n",
    "\n",
    "# suffle the file names for training\n",
    "np.random.shuffle(train_tfrecords_filenames)\n",
    "print(\"Training file names: \", train_tfrecords_filenames)\n",
    "print(\"Validation file names: \", val_tfrecords_filenames)\n",
    "\n",
    "windowLength = 256\n",
    "overlap      = round(0.25 * windowLength) # overlap of 75%\n",
    "ffTLength    = windowLength\n",
    "inputFs      = 48e3\n",
    "fs           = 16e3\n",
    "numFeatures  = ffTLength//2 + 1\n",
    "numSegments  = 8\n",
    "print(\"windowLength:\",windowLength)\n",
    "print(\"overlap:\",overlap)\n",
    "print(\"ffTLength:\",ffTLength)\n",
    "print(\"inputFs:\",inputFs)\n",
    "print(\"fs:\",fs)\n",
    "print(\"numFeatures:\",numFeatures)\n",
    "print(\"numSegments:\",numSegments)\n",
    "\n",
    "mozilla_basepath = os.getenv('HOME')+ \"/data/en\"\n",
    "UrbanSound8K_basepath = os.getenv('HOME')+ '/data/UrbanSound8K'\n",
    "\n",
    "## Prepare Input features\n",
    "\n",
    "def tf_record_parser(record):\n",
    "    keys_to_features = {\n",
    "        \"noise_stft_phase\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        'noise_stft_mag_features': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"clean_stft_magnitude\": tf.io.FixedLenFeature((), tf.string)\n",
    "    }\n",
    "\n",
    "    features = tf.io.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    noise_stft_mag_features = tf.io.decode_raw(features['noise_stft_mag_features'], tf.float32)\n",
    "    clean_stft_magnitude = tf.io.decode_raw(features['clean_stft_magnitude'], tf.float32)\n",
    "    noise_stft_phase = tf.io.decode_raw(features['noise_stft_phase'], tf.float32)\n",
    "\n",
    "    # reshape input and annotation images\n",
    "    noise_stft_mag_features = tf.reshape(noise_stft_mag_features, (129, 8, 1), name=\"noise_stft_mag_features\")\n",
    "    clean_stft_magnitude = tf.reshape(clean_stft_magnitude, (129, 1, 1), name=\"clean_stft_magnitude\")\n",
    "    noise_stft_phase = tf.reshape(noise_stft_phase, (129,), name=\"noise_stft_phase\")\n",
    "\n",
    "    return noise_stft_mag_features, clean_stft_magnitude\n",
    "\n",
    "## Create tf.Data.Dataset\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset([train_tfrecords_filenames])\n",
    "train_dataset = train_dataset.map(tf_record_parser)\n",
    "train_dataset = train_dataset.shuffle(8192)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.batch(512)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.TFRecordDataset([val_tfrecords_filenames])\n",
    "test_dataset = test_dataset.map(tf_record_parser)\n",
    "test_dataset = test_dataset.repeat(1)\n",
    "test_dataset = test_dataset.batch(512)\n",
    "\n",
    "## Model Training\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "def conv_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
    "  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  if use_bn:\n",
    "    x = BatchNormalization()(x)\n",
    "  return x\n",
    "\n",
    "def full_pre_activation_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
    "  shortcut = x\n",
    "  in_channels = x.shape[-1]\n",
    "\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters=in_channels, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "\n",
    "  return shortcut + x\n",
    "\n",
    "def build_model(l2_strength):\n",
    "  inputs = Input(shape=[numFeatures,numSegments,1])\n",
    "  x = inputs\n",
    "\n",
    "  # -----\n",
    "  x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n",
    "  x = Conv2D(filters=18, kernel_size=[9,8], strides=[1, 1], padding='valid', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  skip0 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(skip0)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # -----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  skip1 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(skip1)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = x + skip1\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = x + skip0\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n",
    "  x = Conv2D(filters=1, kernel_size=[129,1], strides=[1, 1], padding='same')(x)\n",
    "\n",
    "  model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(3e-4)\n",
    "  #optimizer = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=3e-4)\n",
    "\n",
    "  model.compile(optimizer=optimizer, loss='mse', \n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError('rmse')])\n",
    "  return model\n",
    "\n",
    "model = build_model(l2_strength=0.0)\n",
    "model.summary()\n",
    "\n",
    "# You might need to install the following dependencies: sudo apt install python-pydot python-pydot-ng graphviz\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)\n",
    "\n",
    "%tensorboard --logdir logs\n",
    "\n",
    "baseline_val_loss = model.evaluate(test_dataset)[0]\n",
    "print(f\"Baseline accuracy {baseline_val_loss}\")\n",
    "\n",
    "def l2_norm(vector):\n",
    "    return np.square(vector)\n",
    "\n",
    "def SDR(denoised, cleaned, eps=1e-7): # Signal to Distortion Ratio\n",
    "    a = l2_norm(denoised)\n",
    "    b = l2_norm(denoised - cleaned)\n",
    "    a_b = a / b\n",
    "    return np.mean(10 * np.log10(a_b + eps))\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, baseline=None)\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq='batch')\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./denoiser_cnn_log_mel_generator.h5', \n",
    "                                                         monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(train_dataset,\n",
    "         steps_per_epoch=600, # you might need to change this\n",
    "         validation_data=test_dataset,\n",
    "         epochs=400,\n",
    "         callbacks=[early_stopping_callback, tensorboard_callback, checkpoint_callback]\n",
    "        )\n",
    "\n",
    "val_loss = model.evaluate(test_dataset)[0]\n",
    "if val_loss < baseline_val_loss:\n",
    "  print(\"New model saved.\")\n",
    "  model.save('./denoiser_cnn_log_mel_generator.h5')\n",
    "\n",
    "## Testing\n",
    "\n",
    "def read_audio(filepath, sample_rate, normalize=True):\n",
    "    \"\"\"Read an audio file and return it as a numpy array\"\"\"\n",
    "    audio, sr = librosa.load(filepath, sr=sample_rate)\n",
    "    if normalize:\n",
    "      div_fac = 1 / np.max(np.abs(audio)) / 3.0\n",
    "      audio = audio * div_fac\n",
    "    return audio, sr\n",
    "        \n",
    "def add_noise_to_clean_audio(clean_audio, noise_signal):\n",
    "    \"\"\"Adds noise to an audio sample\"\"\"\n",
    "    if len(clean_audio) >= len(noise_signal):\n",
    "        # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n",
    "        while len(clean_audio) >= len(noise_signal):\n",
    "            noise_signal = np.append(noise_signal, noise_signal)\n",
    "\n",
    "    ## Extract a noise segment from a random location in the noise file\n",
    "    ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n",
    "\n",
    "    noiseSegment = noise_signal[ind: ind + clean_audio.size]\n",
    "\n",
    "    speech_power = np.sum(clean_audio ** 2)\n",
    "    noise_power = np.sum(noiseSegment ** 2)\n",
    "    noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n",
    "    return noisyAudio\n",
    "\n",
    "def play(audio, sample_rate):\n",
    "    ipd.display(ipd.Audio(data=audio, rate=sample_rate))  # load a local WAV file\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n",
    "        self.audio = audio\n",
    "        self.ffT_length = windowLength\n",
    "        self.window_length = windowLength\n",
    "        self.overlap = overlap\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window = scipy.signal.hamming(self.window_length, sym=False)\n",
    "\n",
    "    def get_stft_spectrogram(self):\n",
    "        return librosa.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n",
    "                            window=self.window, center=True)\n",
    "\n",
    "    def get_audio_from_stft_spectrogram(self, stft_features):\n",
    "        return librosa.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n",
    "                             window=self.window, center=True)\n",
    "\n",
    "    def get_mel_spectrogram(self):\n",
    "        return librosa.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, pad_mode='reflect',\n",
    "                                           n_fft=self.ffT_length, hop_length=self.overlap, center=True)\n",
    "\n",
    "    def get_audio_from_mel_spectrogram(self, M):\n",
    "        return librosa.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length, hop_length=self.overlap,\n",
    "                                             win_length=self.window_length, window=self.window,\n",
    "                                             center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)\n",
    "\n",
    "cleanAudio, sr = read_audio(os.path.join(mozilla_basepath, 'test', 'common_voice_en_16526.mp3'), sample_rate=fs)\n",
    "print(\"Min:\", np.min(cleanAudio),\"Max:\",np.max(cleanAudio))\n",
    "ipd.Audio(data=cleanAudio, rate=sr) # load a local WAV file\n",
    "\n",
    "noiseAudio, sr = read_audio(os.path.join(UrbanSound8K_basepath, 'test', '7913-3-0-0.wav'), sample_rate=fs)\n",
    "print(\"Min:\", np.min(noiseAudio),\"Max:\",np.max(noiseAudio))\n",
    "ipd.Audio(data=noiseAudio, rate=sr) # load a local WAV file\n",
    "\n",
    "cleanAudioFeatureExtractor = FeatureExtractor(cleanAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "stft_features = cleanAudioFeatureExtractor.get_stft_spectrogram()\n",
    "stft_features = np.abs(stft_features)\n",
    "print(\"Min:\", np.min(stft_features),\"Max:\",np.max(stft_features))\n",
    "\n",
    "noisyAudio = add_noise_to_clean_audio(cleanAudio, noiseAudio)\n",
    "ipd.Audio(data=noisyAudio, rate=fs) # load a local WAV file\n",
    "\n",
    "def prepare_input_features(stft_features):\n",
    "    # Phase Aware Scaling: To avoid extreme differences (more than\n",
    "    # 45 degree) between the noisy and clean phase, the clean spectral magnitude was encoded as similar to [21]:\n",
    "    noisySTFT = np.concatenate([stft_features[:,0:numSegments-1], stft_features], axis=1)\n",
    "    stftSegments = np.zeros((numFeatures, numSegments , noisySTFT.shape[1] - numSegments + 1))\n",
    "\n",
    "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
    "        stftSegments[:,:,index] = noisySTFT[:,index:index + numSegments]\n",
    "    return stftSegments\n",
    "\n",
    "noiseAudioFeatureExtractor = FeatureExtractor(noisyAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "noise_stft_features = noiseAudioFeatureExtractor.get_stft_spectrogram()\n",
    "\n",
    "# Paper: Besides, spectral phase was not used in the training phase.\n",
    "# At reconstruction, noisy spectral phase was used instead to\n",
    "# perform in- verse STFT and recover human speech.\n",
    "noisyPhase = np.angle(noise_stft_features)\n",
    "print(noisyPhase.shape)\n",
    "noise_stft_features = np.abs(noise_stft_features)\n",
    "\n",
    "mean = np.mean(noise_stft_features)\n",
    "std = np.std(noise_stft_features)\n",
    "noise_stft_features = (noise_stft_features - mean) / std\n",
    "\n",
    "predictors = prepare_input_features(noise_stft_features)\n",
    "\n",
    "predictors = np.reshape(predictors, (predictors.shape[0], predictors.shape[1], 1, predictors.shape[2]))\n",
    "predictors = np.transpose(predictors, (3, 0, 1, 2)).astype(np.float32)\n",
    "print('predictors.shape:', predictors.shape)\n",
    "\n",
    "STFTFullyConvolutional = model.predict(predictors)\n",
    "print(STFTFullyConvolutional.shape)\n",
    "\n",
    "def revert_features_to_audio(features, phase, cleanMean=None, cleanStd=None):\n",
    "    # scale the outpus back to the original range\n",
    "    if cleanMean and cleanStd:\n",
    "        features = cleanStd * features + cleanMean\n",
    "\n",
    "    phase = np.transpose(phase, (1, 0))\n",
    "    features = np.squeeze(features)\n",
    "\n",
    "    # features = librosa.db_to_power(features)\n",
    "    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n",
    "\n",
    "    features = np.transpose(features, (1, 0))\n",
    "    return noiseAudioFeatureExtractor.get_audio_from_stft_spectrogram(features)\n",
    "\n",
    "denoisedAudioFullyConvolutional = revert_features_to_audio(STFTFullyConvolutional, noisyPhase, mean, std)\n",
    "print(\"Min:\", np.min(denoisedAudioFullyConvolutional),\"Max:\",np.max(denoisedAudioFullyConvolutional))\n",
    "ipd.Audio(data=denoisedAudioFullyConvolutional, rate=fs) # load a local WAV file\n",
    "\n",
    "# A numeric identifier of the sound class -- Types of noise\n",
    "# 0 = air_conditioner\n",
    "# 1 = car_horn\n",
    "# 2 = children_playing\n",
    "# 3 = dog_bark\n",
    "# 4 = drilling\n",
    "# 5 = engine_idling\n",
    "# 6 = gun_shot\n",
    "# 7 = jackhammer\n",
    "# 8 = siren\n",
    "# 9 = street_music\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharey=True)\n",
    "\n",
    "ax1.plot(cleanAudio)\n",
    "ax1.set_title(\"Clean Audio\")\n",
    "\n",
    "ax2.plot(noisyAudio)\n",
    "ax2.set_title(\"Noisy Audio\")\n",
    "\n",
    "ax3.plot(denoisedAudioFullyConvolutional)\n",
    "ax3.set_title(\"Denoised Audio\")\n",
    "\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "device_name\n",
    "# if device_name != '/device:XLA_GPUGPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4db211",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba71f7c",
   "metadata": {
    "id": "Ah7ISzvtEmur"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import scipy\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import zipfile\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617838c",
   "metadata": {
    "id": "WBZyUMpobR-Z"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0125389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((129,8,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a96d3",
   "metadata": {
    "id": "zu2lgR8lEmu0"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(999)\n",
    "np.random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data_processing/urban_sound_8K.py\n",
    "!python data_processing/mozilla_common_voice.py\n",
    "!python data_processing/feature_extractor.py\n",
    "!python data_processing/dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data_processing/create_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a2188",
   "metadata": {
    "id": "JGbkvQHxxrj_"
   },
   "outputs": [],
   "source": [
    "# !wget 'cdn.daitan.com/dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae5ec2e",
   "metadata": {
    "id": "51o6Ze9hxrkE"
   },
   "outputs": [],
   "source": [
    "# os.getenv('HOME')+'/data'\n",
    "dataset_file_name = './dataset.zip'\n",
    "with zipfile.ZipFile(dataset_file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d541481",
   "metadata": {
    "id": "d43UvhEqxrkJ"
   },
   "outputs": [],
   "source": [
    "path_to_dataset = os.getenv('HOME')+'/data/tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89aac99",
   "metadata": {
    "id": "W36WF4mT1kGK"
   },
   "outputs": [],
   "source": [
    "# get training and validation tf record file names\n",
    "train_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'train_*'))\n",
    "val_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'val_*'))\n",
    "\n",
    "# suffle the file names for training\n",
    "np.random.shuffle(train_tfrecords_filenames)\n",
    "print(\"Training file names: \", train_tfrecords_filenames)\n",
    "print(\"Validation file names: \", val_tfrecords_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9d56e",
   "metadata": {
    "id": "jKZtPoLMEmvJ"
   },
   "outputs": [],
   "source": [
    "windowLength = 256\n",
    "overlap      = round(0.25 * windowLength) # overlap of 75%\n",
    "ffTLength    = windowLength\n",
    "inputFs      = 48e3\n",
    "fs           = 16e3\n",
    "numFeatures  = ffTLength//2 + 1\n",
    "numSegments  = 8\n",
    "print(\"windowLength:\",windowLength)\n",
    "print(\"overlap:\",overlap)\n",
    "print(\"ffTLength:\",ffTLength)\n",
    "print(\"inputFs:\",inputFs)\n",
    "print(\"fs:\",fs)\n",
    "print(\"numFeatures:\",numFeatures)\n",
    "print(\"numSegments:\",numSegments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3dbf95",
   "metadata": {
    "id": "JXpSGe8L0cl_"
   },
   "outputs": [],
   "source": [
    "mozilla_basepath = os.getenv('HOME')+ \"/data/en\"\n",
    "UrbanSound8K_basepath = os.getenv('HOME')+ '/data/UrbanSound8K'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da058233",
   "metadata": {
    "id": "zzbdfIi-Lgk9"
   },
   "source": [
    "## Prepare Input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676e091",
   "metadata": {
    "id": "24kph3wJ3s5V"
   },
   "outputs": [],
   "source": [
    "def tf_record_parser(record):\n",
    "    keys_to_features = {\n",
    "        \"noise_stft_phase\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        'noise_stft_mag_features': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"clean_stft_magnitude\": tf.io.FixedLenFeature((), tf.string)\n",
    "    }\n",
    "\n",
    "    features = tf.io.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    noise_stft_mag_features = tf.io.decode_raw(features['noise_stft_mag_features'], tf.float32)\n",
    "    clean_stft_magnitude = tf.io.decode_raw(features['clean_stft_magnitude'], tf.float32)\n",
    "    noise_stft_phase = tf.io.decode_raw(features['noise_stft_phase'], tf.float32)\n",
    "\n",
    "    # reshape input and annotation images\n",
    "    noise_stft_mag_features = tf.reshape(noise_stft_mag_features, (129, 8, 1), name=\"noise_stft_mag_features\")\n",
    "    clean_stft_magnitude = tf.reshape(clean_stft_magnitude, (129, 1, 1), name=\"clean_stft_magnitude\")\n",
    "    noise_stft_phase = tf.reshape(noise_stft_phase, (129,), name=\"noise_stft_phase\")\n",
    "\n",
    "    return noise_stft_mag_features, clean_stft_magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6911050",
   "metadata": {
    "id": "uJXPGrgVTCbZ"
   },
   "source": [
    "## Create tf.Data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da9754",
   "metadata": {
    "id": "FF_A3YbZTCsj"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset([train_tfrecords_filenames])\n",
    "train_dataset = train_dataset.map(tf_record_parser)\n",
    "train_dataset = train_dataset.shuffle(8192)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.batch(512)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283a766",
   "metadata": {
    "id": "NOuWPzQaTNDy"
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.TFRecordDataset([val_tfrecords_filenames])\n",
    "test_dataset = test_dataset.map(tf_record_parser)\n",
    "test_dataset = test_dataset.repeat(1)\n",
    "test_dataset = test_dataset.batch(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6309f",
   "metadata": {
    "id": "CEG5JofLSfRw"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18d6e0",
   "metadata": {
    "id": "2OZFegXrSYle"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n",
    "from tensorflow.keras import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffe7a0",
   "metadata": {
    "id": "lc2K0cfhPU5-"
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
    "  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  if use_bn:\n",
    "    x = BatchNormalization()(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36272076",
   "metadata": {
    "id": "XFYyKoAVQYCz"
   },
   "outputs": [],
   "source": [
    "def full_pre_activation_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
    "  shortcut = x\n",
    "  in_channels = x.shape[-1]\n",
    "\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters=in_channels, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "\n",
    "  return shortcut + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485cc254",
   "metadata": {
    "id": "NlRQ3ngpZG1Y"
   },
   "outputs": [],
   "source": [
    "def build_model(l2_strength):\n",
    "  inputs = Input(shape=[numFeatures,numSegments,1])\n",
    "  x = inputs\n",
    "\n",
    "  # -----\n",
    "  x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n",
    "  x = Conv2D(filters=18, kernel_size=[9,8], strides=[1, 1], padding='valid', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  skip0 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(skip0)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # -----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  skip1 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(skip1)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = x + skip1\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = x + skip0\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # ----\n",
    "  x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n",
    "  x = Conv2D(filters=1, kernel_size=[129,1], strides=[1, 1], padding='same')(x)\n",
    "\n",
    "  model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(3e-4)\n",
    "  #optimizer = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=3e-4)\n",
    "\n",
    "  model.compile(optimizer=optimizer, loss='mse', \n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError('rmse')])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f674db",
   "metadata": {
    "id": "mNpHS4LuShxd"
   },
   "outputs": [],
   "source": [
    "model = build_model(l2_strength=0.0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83265add",
   "metadata": {
    "id": "8rWOgsdwglFE"
   },
   "outputs": [],
   "source": [
    "# You might need to install the following dependencies: sudo apt install python-pydot python-pydot-ng graphviz\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1217c",
   "metadata": {
    "id": "7OdmgHTp4_Ou"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b9f0e",
   "metadata": {
    "id": "BucSAwkHQj8Q"
   },
   "outputs": [],
   "source": [
    "baseline_val_loss = model.evaluate(test_dataset)[0]\n",
    "print(f\"Baseline accuracy {baseline_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7dae8",
   "metadata": {
    "id": "ocycFbP5-X0o"
   },
   "outputs": [],
   "source": [
    "def l2_norm(vector):\n",
    "    return np.square(vector)\n",
    "\n",
    "def SDR(denoised, cleaned, eps=1e-7): # Signal to Distortion Ratio\n",
    "    a = l2_norm(denoised)\n",
    "    b = l2_norm(denoised - cleaned)\n",
    "    a_b = a / b\n",
    "    return np.mean(10 * np.log10(a_b + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476dac6",
   "metadata": {
    "id": "bcPAuMZ9SlHa"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, baseline=None)\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq='batch')\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./denoiser_cnn_log_mel_generator.h5', \n",
    "                                                         monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(train_dataset,\n",
    "         steps_per_epoch=600, # you might need to change this\n",
    "         validation_data=test_dataset,\n",
    "         epochs=400,\n",
    "         callbacks=[early_stopping_callback, tensorboard_callback, checkpoint_callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12ad6a",
   "metadata": {
    "id": "g1ZZskDZ5L2a"
   },
   "outputs": [],
   "source": [
    "val_loss = model.evaluate(test_dataset)[0]\n",
    "if val_loss < baseline_val_loss:\n",
    "  print(\"New model saved.\")\n",
    "  model.save('./denoiser_cnn_log_mel_generator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f850d",
   "metadata": {
    "id": "LeJTsGxCSuhm"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d4420",
   "metadata": {
    "id": "DLiTiK8blE0n"
   },
   "outputs": [],
   "source": [
    "def read_audio(filepath, sample_rate, normalize=True):\n",
    "    \"\"\"Read an audio file and return it as a numpy array\"\"\"\n",
    "    audio, sr = librosa.load(filepath, sr=sample_rate)\n",
    "    if normalize:\n",
    "      div_fac = 1 / np.max(np.abs(audio)) / 3.0\n",
    "      audio = audio * div_fac\n",
    "    return audio, sr\n",
    "        \n",
    "def add_noise_to_clean_audio(clean_audio, noise_signal):\n",
    "    \"\"\"Adds noise to an audio sample\"\"\"\n",
    "    if len(clean_audio) >= len(noise_signal):\n",
    "        # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n",
    "        while len(clean_audio) >= len(noise_signal):\n",
    "            noise_signal = np.append(noise_signal, noise_signal)\n",
    "\n",
    "    ## Extract a noise segment from a random location in the noise file\n",
    "    ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n",
    "\n",
    "    noiseSegment = noise_signal[ind: ind + clean_audio.size]\n",
    "\n",
    "    speech_power = np.sum(clean_audio ** 2)\n",
    "    noise_power = np.sum(noiseSegment ** 2)\n",
    "    noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n",
    "    return noisyAudio\n",
    "\n",
    "def play(audio, sample_rate):\n",
    "    ipd.display(ipd.Audio(data=audio, rate=sample_rate))  # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b5338",
   "metadata": {
    "id": "uM6ajbBFlx3b"
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n",
    "        self.audio = audio\n",
    "        self.ffT_length = windowLength\n",
    "        self.window_length = windowLength\n",
    "        self.overlap = overlap\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window = scipy.signal.hamming(self.window_length, sym=False)\n",
    "\n",
    "    def get_stft_spectrogram(self):\n",
    "        return librosa.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n",
    "                            window=self.window, center=True)\n",
    "\n",
    "    def get_audio_from_stft_spectrogram(self, stft_features):\n",
    "        return librosa.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n",
    "                             window=self.window, center=True)\n",
    "\n",
    "    def get_mel_spectrogram(self):\n",
    "        return librosa.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, pad_mode='reflect',\n",
    "                                           n_fft=self.ffT_length, hop_length=self.overlap, center=True)\n",
    "\n",
    "    def get_audio_from_mel_spectrogram(self, M):\n",
    "        return librosa.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length, hop_length=self.overlap,\n",
    "                                             win_length=self.window_length, window=self.window,\n",
    "                                             center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda31d3e",
   "metadata": {
    "id": "9dcnyvquSoLs"
   },
   "outputs": [],
   "source": [
    "cleanAudio, sr = read_audio(os.path.join(mozilla_basepath, 'test', 'common_voice_en_16526.mp3'), sample_rate=fs)\n",
    "print(\"Min:\", np.min(cleanAudio),\"Max:\",np.max(cleanAudio))\n",
    "ipd.Audio(data=cleanAudio, rate=sr) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e00ea4",
   "metadata": {
    "id": "BaHe1okPTvV-"
   },
   "outputs": [],
   "source": [
    "noiseAudio, sr = read_audio(os.path.join(UrbanSound8K_basepath, 'test', '7913-3-0-0.wav'), sample_rate=fs)\n",
    "print(\"Min:\", np.min(noiseAudio),\"Max:\",np.max(noiseAudio))\n",
    "ipd.Audio(data=noiseAudio, rate=sr) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c11b1d",
   "metadata": {
    "id": "bu_eOKRfTHbp"
   },
   "outputs": [],
   "source": [
    "cleanAudioFeatureExtractor = FeatureExtractor(cleanAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "stft_features = cleanAudioFeatureExtractor.get_stft_spectrogram()\n",
    "stft_features = np.abs(stft_features)\n",
    "print(\"Min:\", np.min(stft_features),\"Max:\",np.max(stft_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8968e",
   "metadata": {
    "id": "sHWcmobyTP4E"
   },
   "outputs": [],
   "source": [
    "noisyAudio = add_noise_to_clean_audio(cleanAudio, noiseAudio)\n",
    "ipd.Audio(data=noisyAudio, rate=fs) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34251e",
   "metadata": {
    "id": "75M29dl3bBeF"
   },
   "outputs": [],
   "source": [
    "def prepare_input_features(stft_features):\n",
    "    # Phase Aware Scaling: To avoid extreme differences (more than\n",
    "    # 45 degree) between the noisy and clean phase, the clean spectral magnitude was encoded as similar to [21]:\n",
    "    noisySTFT = np.concatenate([stft_features[:,0:numSegments-1], stft_features], axis=1)\n",
    "    stftSegments = np.zeros((numFeatures, numSegments , noisySTFT.shape[1] - numSegments + 1))\n",
    "\n",
    "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
    "        stftSegments[:,:,index] = noisySTFT[:,index:index + numSegments]\n",
    "    return stftSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3f2e7",
   "metadata": {
    "id": "9cjO5-cjTP6t"
   },
   "outputs": [],
   "source": [
    "noiseAudioFeatureExtractor = FeatureExtractor(noisyAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "noise_stft_features = noiseAudioFeatureExtractor.get_stft_spectrogram()\n",
    "\n",
    "# Paper: Besides, spectral phase was not used in the training phase.\n",
    "# At reconstruction, noisy spectral phase was used instead to\n",
    "# perform in- verse STFT and recover human speech.\n",
    "noisyPhase = np.angle(noise_stft_features)\n",
    "print(noisyPhase.shape)\n",
    "noise_stft_features = np.abs(noise_stft_features)\n",
    "\n",
    "mean = np.mean(noise_stft_features)\n",
    "std = np.std(noise_stft_features)\n",
    "noise_stft_features = (noise_stft_features - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52137b04",
   "metadata": {
    "id": "3p5PWWkrlE3m"
   },
   "outputs": [],
   "source": [
    "predictors = prepare_input_features(noise_stft_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106365a",
   "metadata": {
    "id": "4pSoOw2fTP9N"
   },
   "outputs": [],
   "source": [
    "predictors = np.reshape(predictors, (predictors.shape[0], predictors.shape[1], 1, predictors.shape[2]))\n",
    "predictors = np.transpose(predictors, (3, 0, 1, 2)).astype(np.float32)\n",
    "print('predictors.shape:', predictors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b0659",
   "metadata": {
    "id": "a5sNR4sSTP_1"
   },
   "outputs": [],
   "source": [
    "STFTFullyConvolutional = model.predict(predictors)\n",
    "print(STFTFullyConvolutional.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac16e4",
   "metadata": {
    "id": "LzCga3PdUVwG"
   },
   "outputs": [],
   "source": [
    "def revert_features_to_audio(features, phase, cleanMean=None, cleanStd=None):\n",
    "    # scale the outpus back to the original range\n",
    "    if cleanMean and cleanStd:\n",
    "        features = cleanStd * features + cleanMean\n",
    "\n",
    "    phase = np.transpose(phase, (1, 0))\n",
    "    features = np.squeeze(features)\n",
    "\n",
    "    # features = librosa.db_to_power(features)\n",
    "    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n",
    "\n",
    "    features = np.transpose(features, (1, 0))\n",
    "    return noiseAudioFeatureExtractor.get_audio_from_stft_spectrogram(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a80f2",
   "metadata": {
    "id": "LWlUDtPzURlQ"
   },
   "outputs": [],
   "source": [
    "denoisedAudioFullyConvolutional = revert_features_to_audio(STFTFullyConvolutional, noisyPhase, mean, std)\n",
    "print(\"Min:\", np.min(denoisedAudioFullyConvolutional),\"Max:\",np.max(denoisedAudioFullyConvolutional))\n",
    "ipd.Audio(data=denoisedAudioFullyConvolutional, rate=fs) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4215763",
   "metadata": {
    "id": "VvEIBy7EHgeP"
   },
   "outputs": [],
   "source": [
    "# A numeric identifier of the sound class -- Types of noise\n",
    "# 0 = air_conditioner\n",
    "# 1 = car_horn\n",
    "# 2 = children_playing\n",
    "# 3 = dog_bark\n",
    "# 4 = drilling\n",
    "# 5 = engine_idling\n",
    "# 6 = gun_shot\n",
    "# 7 = jackhammer\n",
    "# 8 = siren\n",
    "# 9 = street_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5c35b",
   "metadata": {
    "id": "tv_7ZwWaUW0_"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharey=True)\n",
    "\n",
    "ax1.plot(cleanAudio)\n",
    "ax1.set_title(\"Clean Audio\")\n",
    "\n",
    "ax2.plot(noisyAudio)\n",
    "ax2.set_title(\"Noisy Audio\")\n",
    "\n",
    "ax3.plot(denoisedAudioFullyConvolutional)\n",
    "ax3.set_title(\"Denoised Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19918ae9",
   "metadata": {
    "id": "8LM7E91avKA3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7b4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
